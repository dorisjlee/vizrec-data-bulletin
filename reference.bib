@article{Anand2015,
author = {Anand, Anushka and Talbot, Justin},
doi = {10.1109/TVCG.2015.2467323},
file = {:Users/dorislee/Dropbox/Papers/Anand, Talbot{\_}2015{\_}Automatic Selection of Partitioning Variables for Small Multiple Displays.pdf:pdf},
number = {c},
title = {{Automatic Selection of Partitioning Variables for Small Multiple Displays}},
volume = {2626},
year = {2015}
}
@article{Sarvghad2017,
abstract = {Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets [30] to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.},
author = {Sarvghad, Ali and Tory, Melanie and Mahyar, Narges},
doi = {10.1109/TVCG.2016.2598466},
file = {:Users/dorislee/Box/Papers/07534787.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Dimension coverage,Empirical laboratory study,Exploratory data analysis,History,Scented widgets,Tabular data},
number = {1},
pages = {21--30},
title = {{Visualizing Dimension Coverage to Support Exploratory Analysis}},
volume = {23},
year = {2017}
}

@misc{police,
author = "Pierson, E. and Simoiu, C. and Overgoor, J. and Corbett-Davies, S. and  Ramachandran, V. and Phillips, C. and Goel, S.",
year = "2017",
title = "A large-scale analysis of racial disparities in police stops across the United States",
url = "https://openpolicing.stanford.edu/data/",
institution = "The Stanford Open Policing Project"
}

@article{Vartak2015,
author = {Vartak, Manasi and Madden, Samuel and Parmeswaran, Aditya N},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Vartak, Madden, Parmeswaran - 2015 - SEEDB Supporting Visual Analytics with Data-Driven Recommendations.pdf:pdf},
mendeley-groups = {HILDA,Database Usability,ieee-data-bulletin},
title = {{SEEDB : Supporting Visual Analytics with Data-Driven Recommendations}},
year = {2015}
}
@article{Wongsuphasawat2017,
author = {Wongsuphasawat, Kanit and Qu, Zening and Moritz, Dominik and Chang, Riley and Ouk, Felix and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
doi = {10.1145/3025453.3025768},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Wongsuphasawat et al. - 2017 - Voyager 2 Augmenting Visual Analysis with Partial View Specifications.pdf:pdf},
isbn = {9781450346559},
mendeley-groups = {Database Usability,ieee-data-bulletin},
title = {{Voyager 2 : Augmenting Visual Analysis with Partial View Specifications}},
year = {2017}
}
@article{Siddiqui2016,
 author = {Siddiqui, Tarique and Kim, Albert and Lee, John and Karahalios, Karrie and Parameswaran, Aditya},
 title = {Effortless Data Exploration with Zenvisage: An Expressive and Interactive Visual Analytics System},
 journal = {Proc. VLDB Endow.},
 issue_date = {November 2016},
 volume = {10},
 number = {4},
 month = nov,
 year = {2016},
 issn = {2150-8097},
 pages = {457--468},
 numpages = {12},
 url = {https://doi.org/10.14778/3025111.3025126},
 doi = {10.14778/3025111.3025126},
 acmid = {3025126},
 publisher = {VLDB Endowment},
} 
[download]

@article{Vartak2017,
abstract = {â€” Data visualization is often used as the first step while performing a variety of analytical tasks. With the advent of large, high-dimensional datasets and strong interest in data science, there is a need for tools that can support rapid visual analysis. In this paper we describe our vision for a new class of visualization recommendation systems that can automatically identify and interactively recommend visualizations relevant to an analytical task.},
author = {Vartak, Manasi and Huang, Silu and Siddiqui, Tarique and Madden, Samuel and Parameswaran, Aditya},
doi = {10.1145/3092931.3092937},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Vartak et al. - 2017 - Towards Visualization Recommendation Systems.pdf:pdf},
isbn = {01635808},
issn = {01635808},
journal = {ACM SIGMOD Record},
mendeley-groups = {ieee-data-bulletin},
number = {4},
pages = {34--39},
title = {{Towards Visualization Recommendation Systems}},
url = {http://dl.acm.org/citation.cfm?doid=3092931.3092937},
volume = {45},
year = {2017}
}
@article{Dibia2017,
abstract = {The pervasive presence of interconnected objects enables new communication paradigms where devices can easily reach each other while interacting within their environment. The so-called Internet of Things (IoT) represents the integration of several computing and communications systems aiming at facilitating the interaction between these devices. Arduino is one of the most popular platforms used to prototype new IoT devices due to its open, flexible and easy-to-use archi- tecture. Ardunio Yun is a dual board microcontroller that supports a Linux distribution and it is currently one of the most versatile and powerful Arduino systems. This feature positions Arduino Yun as a popular platform for developers, but it also introduces unique infection vectors from the secu- rity viewpoint. In this work, we present a security analysis of Arduino Yun. We show that Arduino Yun is vulnerable to a number of attacks and we implement a proof of concept capable of exploiting some of them.},
archivePrefix = {arXiv},
arxivId = {arXiv:1603.07016v1},
author = {Dibia, Victor and Demiralp, Cagatay},
doi = {10.1145/1235},
eprint = {arXiv:1603.07016v1},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Dibia, Demiralp - 2017 - Data2Vis Automatic Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Networks.pdf:pdf},
isbn = {9781450321389},
issn = {16130073},
keywords = {Multimodal learning analytics,Multimodal teaching analytics,STEM education,Sensors,Smart classroom,Smart school},
mendeley-groups = {ieee-data-bulletin},
pages = {53--59},
pmid = {214160309},
title = {{Data2Vis: Automatic Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Networks}},
volume = {1828},
year = {2017}
}
@article{Lee2017,
  author    = {Doris Jung{-}Lin Lee and
               John Lee and
               Tarique Siddiqui and
               Jaewoo Kim and
               Karrie Karahalios and
               Aditya G. Parameswaran},
  title     = {Accelerating Scientific Data Exploration via Visual Query Systems},
  journal   = {CoRR},
  volume    = {abs/1710.00763},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.00763},
  archivePrefix = {arXiv},
  eprint    = {1710.00763},
  timestamp = {Wed, 01 Nov 2017 19:05:42 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1710-00763},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Wu2013,
abstract = {Database users commonly explore large data sets by running ag-gregate queries that project the data down to a smaller number of points and dimensions, and visualizing the results. Often, such vi-sualizations will reveal outliers that correspond to errors or surpris-ing features of the input data set. Unfortunately, databases and vi-sualization systems do not provide a way to work backwards from an outlier point to the common properties of the (possibly many) unaggregated input tuples that correspond to that outlier. We pro-pose Scorpion, a system that takes a set of user-specified outlier points in an aggregate query result as input and finds predicates that explain the outliers in terms of properties of the input tuples that are used to compute the selected outlier results. Specifically, this explanation identifies predicates that, when applied to the in-put data, cause the outliers to disappear from the output. To find such predicates, we develop a notion of influence of a predicate on a given output, and design several algorithms that efficiently search for maximum influence predicates over the input data. We show that these algorithms can quickly find outliers in two real data sets (from a sensor deployment and a campaign finance data set), and run orders of magnitude faster than a naive search algorithm while providing comparable quality on a synthetic data set.},
author = {Wu, Eugene and Madden, Samuel},
doi = {10.14778/2536354.2536356},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Wu, Madden - 2013 - Scorpion Explaining Away Outliers in Aggregate Queries.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
mendeley-groups = {Database Usability},
number = {8},
pages = {553--564},
title = {{Scorpion: Explaining Away Outliers in Aggregate Queries}},
volume = {6},
year = {2013}
}
@article{Heer2012,
abstract = {The increasing scale and availability of digital data provides an extraordinary resource for informing public policy, scientific discovery, business strategy, and even our personal lives. To get the most out of such data, however, users must be able to make sense of it: to pursue questions, uncover patterns of interest, and identify (and potentially correct) errors. In concert with data-management systems and statistical algorithms, analysis requires contextualized human judgments regarding the domain-specific significance of the clusters, trends, and outliers discovered in data. Visualization provides a powerful means of making sense of data. By mapping data attributes to visual properties such as position, size, shape, and color, visualization designers leverage perceptual skills to help users discern and interpret patterns within data.11 A single image, however, typically provides answers to, at best, a handful of questions. Instead, visual analysis typically progresses in an iterative process of view creation, exploration, and refinement. Meaningful analysis consists of repeated explorations as users develop insights about significant relationships, domain-specific contextual influences, and causal patterns. Confusing widgets, complex dialog boxes, hidden operations, incomprehensible displays, or slow response times can limit the range and depth of topics considered and may curtail thorough deliberation and introduce errors. To be most effective, visual analytics tools must support the fluent and flexible use of visualizations at rates resonant with the pace of human thought. The goal of this article is to assist designers, researchers, professional analysts, procurement officers, educators, and students in evaluating and creating visual analysis tools. We present a taxonomy of interactive dynamics that contribute to successful analytic dialogues. The taxonomy consists of 12 task types grouped into three high-level categories, as shown in table 1: (1) data and view specification (visualize, filter, sort, and derive); (2) view manipulation (select, navigate, coordinate, and organize); and (3) analysis process and provenance (record, annotate, share, and guide). These categories incorporate the critical tasks that enable iterative visual analysis, including visualization creation, interactive querying, multiview coordination, history, and collaboration. Validating and evolving this taxonomy is a community project that proceeds through feedback, critique, and refinement. Our focus on interactive elements presumes a basic familiarity with visualization design. The merits and frailties of bar charts, scatter plots, timelines, and node-link diagrams, and of the visual-encoding decisions that underlie such graphics, are certainly a central concern, but we will largely pass over them here. A number of articles and books address these topics in great detail,11,12,16,52 and we recommend them to interested readers. Within each branch of the taxonomy presented here, we describe example systems that exhibit useful interaction techniques. To be clear, these examples do not constitute an exhaustive survey; rather, each is intended to convey the nature and diversity of interactive operations. Throughout the article the term analyst refers to someone who uses visual analysis tools and not to a specific person or role. Our notion of analyst encompasses anyone seeking to understand data: traditional analysts investigating financial markets or terrorist networks, scientists uncovering new insights, journalists piecing together a story, and people tracking various facets of their lives, including blood pressure, money spent, electricity used, or miles traveled.},
author = {Heer, Jeffrey and Shneiderman, Ben},
doi = {10.1145/2133416.2146416},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Heer, Shneiderman, Park - 2012 - A taxonomy of tools that support the fluent and flexible use of visualizations.pdf:pdf},
isbn = {1542-7730},
issn = {15427730},
journal = {ACM Queue},
keywords = {filter},
number = {2},
pages = {30},
title = {{Interactive Dynamics for Visual Analysis}},
url = {http://dl.acm.org/citation.cfm?doid=2133416.2146416},
volume = {10},
year = {2012}
}
@article{Pirolli,
author = {Pirolli, Peter and Card, Stuart},
file = {:Users/dorislee/Library/Application Support/Mendeley Desktop/Downloaded/Pirolli et al. - Unknown - The Sensemaking Process and Leverage Points for Analyst Technology as Identified Through Cognitive Task Analy.pdf:pdf},
keywords = {cognitive task analysis,empirical studies,schema,sensemaking},
title = {{The Sensemaking Process and Leverage Points for Analyst Technology as Identified Through Cognitive Task Analysis. A Notional Model of Analyst Sensemaking}}
}

@inproceedings{Wongsuphasawat2016,
 title = {Towards A General-Purpose Query Language for Visualization Recommendation},
 author = {Kanit Wongsuphasawat AND Dominik Moritz AND Anushka Anand AND Jock Mackinlay AND Bill Howe AND Jeffrey Heer},
 booktitle = {ACM SIGMOD Human-in-the-Loop Data Analysis (HILDA)},
 year = {2016},
 url = {http://idl.cs.washington.edu/papers/compassql},
}
@article{Morton2014,
abstract = {We present a vision of next-generation visual analytics ser- vices. We argue that these services should have three related capabilities: support visual and interactive data exploration as they do today, but also suggest relevant data to enrich visualizations, and facilitate the integration and cleaning of that data. Most importantly, they should provide all these capabilities seamlessly in the context of an uninterrupted data analysis cycle. We present the challenges and opportu- nities in building next-generation visual analytics services},
author = {Morton, Kristi and Balazinska, Magdalena and Grossman, Dan and Mackinlay, Jock},
doi = {10.14778/2732279.2732282},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Morton et al. - 2014 - Support the Data Enthusiast Challenges for Next-Generation Data-Analysis Systems.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment, Volume 7, pp. 453â€“456, 2014},
keywords = {challenges for,kristi morton,magdalena balazinska,next-generation data-analysis systems,port the data enthusiast},
mendeley-groups = {Database Usability,HILDA/Viz/Theory/Reviews},
pages = {453--456},
title = {{Support the Data Enthusiast: Challenges for Next-Generation Data-Analysis Systems}},
url = {http://homes.cs.washington.edu/{~}kmorton/p446-morton.pdf},
volume = {7},
year = {2014}
}
@article{Stolte2002,
author = {Stolte, C. and Tang, D. and Hanrahan, P.},
doi = {10.1109/2945.981851},
isbn = {158113567X},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
mendeley-groups = {HILDA/Viz/System},
number = {1},
pages = {1--14},
title = {{Polaris: a system for query, analysis, and visualization of multidimensional relational databases}},
volume = {8},
year = {2002}
}
@book{Wilkinson2005,
 author = {Wilkinson, Leland},
 title = {The Grammar of Graphics (Statistics and Computing)},
 year = {2005},
 isbn = {0387245448},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{Jagadish2007,
 author = {Jagadish, H. V. and Chapman, Adriane and Elkiss, Aaron and Jayapandian, Magesh and Li, Yunyao and Nandi, Arnab and Yu, Cong},
 title = {Making Database Systems Usable},
 booktitle = {Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '07},
 year = {2007},
 isbn = {978-1-59593-686-8},
 location = {Beijing, China},
 pages = {13--24},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1247480.1247483},
 doi = {10.1145/1247480.1247483},
 acmid = {1247483},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {database, usability, user interface},
} 
@article{Sarawagi1998,
author = {Sarawagi, S and Agrawal, R and Megiddo, N and {Univ Politecn Valencia}, Generalitat Valenciana Ajuntament Valencia and {Edbt Fdn}, E T H Zurich Oracle Sybase Softlab Iberia},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Sarawagi et al. - 1998 - Discovery-driven exploration of OLAP data cubes.pdf:pdf},
isbn = {3-540-64264-1},
issn = {03029743},
journal = {6th International Conference on Extending Database Technology (EDBT 98)},
mendeley-groups = {HILDA/Viz/System/VizRec},
pages = {168--182},
title = {{Discovery-driven exploration of OLAP data cubes}},
year = {1998}
}
@article{Sarawagi2000,
abstract = {In this paper we present a tool for enhanced exploration of OLAP data that is adaptive to a user's prior knowledge of the data. The tool continuously keeps track of the parts of the cube that a user has visited. The information in these scattered visited parts of the cube is pieced together to form a model of the user's expected values in the unvisited parts. The mathematical foundation for this modeling is provided by the classical Maximum Entropy principle. At any time, the user can query for ...},
author = {Sarawagi, S.},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Sarawagi - 2000 - User-adaptive exploration of multidimensional data.pdf:pdf},
isbn = {1558607153},
journal = {Proc of the 26th Intl Conference on Very Large},
mendeley-groups = {HILDA/Viz/System/VizRec},
pages = {307--316},
title = {{User-adaptive exploration of multidimensional data}},
url = {http://citeseer.ist.psu.edu/sarawagi00useradaptive.html},
year = {2000}
}

@article{Drlica-Wagner2017,
abstract = {We describe the creation, content, and validation of the Dark Energy Survey (DES) internal year-one cosmology data set, Y1A1 GOLD, in support of upcoming cosmological analyses. The Y1A1 GOLD data set is assembled from multiple epochs of DES imaging and consists of calibrated photometric zeropoints, object catalogs, and ancillary data products - e.g., maps of survey depth and observing conditions, star-galaxy classification, and photometric redshift estimates - that are necessary for accurate cosmological analyses. The Y1A1 GOLD wide-area object catalog consists of {\~{}}137 million objects detected in coadded images covering {\~{}}1800 deg{\$}{\^{}}2{\$} in the DES grizY filters. The 10{\{}$\backslash$sigma{\}} limiting magnitude for galaxies is g = 23.4, r = 23.2, i = 22.5, z = 21.8, and Y = 20.1. Photometric calibration of Y1A1 GOLD was performed by combining nightly zeropoint solutions with stellar-locus regression, and the absolute calibration accuracy is better than 2{\%} over the survey area. DES Y1A1 GOLD is the largest photometric data set at the achieved depth to date, enabling precise measurements of cosmic acceleration at z {\$}\backslashlesssim{\$} 1.},
archivePrefix = {arXiv},
arxivId = {1708.01531},
author = {{Drlica Wagner et al.}},
eprint = {1708.01531},
file = {:Users/dorislee/Dropbox/Papers/Drlica-Wagner et al.{\_}2017{\_}Dark Energy Survey Year 1 Results Photometric Data Set for Cosmology.pdf:pdf},
title = {{Dark Energy Survey Year 1 Results: Photometric Data Set for Cosmology}},
year = {2017}
}
@article{Abouzied2012,
abstract = {Writing complex queries in SQL is a challenge for users. Prior work has developed several techniques to ease query specification but none of these techniques are applicable to a particularly difficult class of queries: quantified queries. Our hypothesis is that users prefer to specify quantified queries interactively by trial-and-error. We identify two impediments to this form of interactive trial-and-error query specification in SQL: (i) changing quantifiers often requires global syntactical query restructuring, and (ii) the absence of non-answers from SQL's results makes verifying query correctness difficult. We remedy these issues with DataPlay, a query tool with an underlying graphical query language, a unique data model and a graphical interface. DataPlay provides two interaction features that support trial-and-error query specification. First, DataPlay allows users to directly manipulate a graphical query by changing quantifiers and modifying dependencies between constraints. Users receive real-time feedback in the form of updated answers and non-answers. Second, DataPlay can auto-correct a user's query, based on user feedback about which tuples to keep or drop from the answers and non-answers. We evaluated the effectiveness of each interaction feature with a user study and we found that direct query manipulation is more effective than auto-correction for simple queries but auto-correction is more effective than direct query manipulation for more complex queries.},
author = {Abouzied, Azza and Hellerstein, J and Silberschatz, A},
doi = {10.1145/2380116.2380144},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Abouzied, Hellerstein, Silberschatz - 2012 - Dataplay interactive tweaking and example-driven correction of graphical database queries.pdf:pdf},
isbn = {9781450315807},
journal = {Proceedings of the 25th annual ACM symposium on User interface software and technology},
mendeley-groups = {Database Usability},
pages = {207--217},
title = {{Dataplay: interactive tweaking and example-driven correction of graphical database queries}},
url = {http://dl.acm.org/citation.cfm?id=2380144},
year = {2012}
}
@article{Zloof1975,
author = {Zloof, Moshe M},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Zloof - Unknown - Query by Example.pdf:pdf},
journal = {National Computer Conference},
pages = {431--438},
title = {{Query by Example}},
year = {1975}
}
@article{Nandi2013,
abstract = {Direct, ad-hoc interaction with databases has typically been per-$\backslash$nformed over console-oriented conversational interfaces using query$\backslash$nlanguages such as SQL. With the rise in popularity of gestural user$\backslash$ninterfaces and computing devices that use gestures as their exclusive$\backslash$nmodes of interaction, database query interfaces require a fundamen-$\backslash$ntal rethinking to work without keyboards. We present a novel query$\backslash$nspecification system that allows the user to query databases using a$\backslash$nseries of gestures. We present a novel gesture recognition system$\backslash$nthat uses both the interaction and the state of the database to classify$\backslash$ngestural input into relational database queries. We conduct exhaus-$\backslash$ntive systems performance tests and user studies to demonstrate that$\backslash$nour system is not only performant and capable of interactive laten-$\backslash$ncies, but it is also more usable, faster to use and more intuitive than$\backslash$nexisting systems.},
author = {Nandi, Arnab and Jiang, Lilong and Mandel, Michael},
doi = {10.14778/2732240.2732247},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Nandi, Jiang, Mandel - 2013 - Gestural query specification.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
mendeley-groups = {Database Usability},
number = {4},
pages = {289--300},
title = {{Gestural query specification}},
url = {http://dl.acm.org/citation.cfm?doid=2732240.2732247},
volume = {7},
year = {2013}
}

@article{Willett2007,
abstract = {This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.},
author = {Willett, Wesley and Heer, Jeffrey and Agrawala, Maneesh},
doi = {10.1109/TVCG.2007.70589},
file = {:Users/dolee/Box/Papers/2007-ScentedWidgets-InfoVis.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Information foraging,Information visualization,Social data analysis,Social navigation,User interface toolkits},
number = {6},
pages = {1129--1136},
pmid = {17968056},
title = {{Scented widgets: Improving navigation cues with embedded visualizations}},
volume = {13},
year = {2007}
}

@article{Olston2003,
abstract = {The two predominant paradigms for finding information on the Web are browsing and keyword searching. While they exhibit complementary advantages, neither paradigm alone is adequate for complex information goals that lend themselves partially to browsing and partially to searching. To integrate browsing and searching smoothly into a single interface, we introduce a novel approach called ScentTrails. Based on the concept of information scent developed in the context of information foraging theory, ScentTrails highlights hyperlinks to indicate paths to search results. This interface enables users to interpolate smoothly between searching and browsing to locate content matching complex information goals effectively. In a preliminary user study, ScentTrails enabled subjects to find information more quickly than by either searching or browsing alone.},
author = {Olston, Christopher and Chi, E D H},
doi = {10.1145/937549.937550},
file = {:Users/dolee/Box/Papers/scenttrails.pdf:pdf},
isbn = {1073-0516},
issn = {10730516},
journal = {ACM Transactions on ComputerHuman Interaction TOCHI},
number = {3},
pages = {177--197},
title = {{ScentTrails: Integrating browsing and searching on the Web}},
url = {http://portal.acm.org/citation.cfm?id=937550{\&}dl=GUIDE{\&}coll=GUIDE{\&}CFID=71207985{\&}CFTOKEN=98903290},
volume = {10},
year = {2003}
}

@article{Setlur2016,
abstract = {Figure 1: Eviza's interface showing a map of earthquake data in the United States. The interface supports natural language analytical questions in the context of a visualization. Here, the map shows marks selected in response to the user's query " find large earthquakes near California. " The system semantically associates the sized descriptor 'large' to an attribute in the dataset called 'magnitude' that can be associated with size. Eviza finds two ambiguities in the query: 'large' and 'near,' which are fuzzy terms for size and distance. The system sets 'large' to be of magnitude 5 and greater, while 'near' is a 100 mile radius around the border of California. Two ambiguity widgets are added to the interface to allow the user to modify these settings. ABSTRACT Natural language interfaces for visualizations have emerged as a promising new way of interacting with data and performing ana-lytics. Many of these systems have fundamental limitations. Most return minimally interactive visualizations in response to queries and often require experts to perform modeling for a set of predicted user queries before the systems are effective. Eviza provides a natural language interface for an interactive query dialog with an existing visualization rather than starting from a blank sheet and ask-ing closed-ended questions that return a single text answer or static visualization. The system employs a probabilistic grammar based approach with predefined rules that are dynamically updated based on the data from the visualization, as opposed to computationally intensive deep learning or knowledge based approaches. The result of an interaction is a change to the view (e.g., filtering, navigation, selection) providing graphical answers and ambiguity widgets to handle ambiguous queries and system defaults. There is also rich domain awareness of time, space, and quantitative reason-ing built in, and linking into existing knowledge bases for additional semantics. Eviza also supports pragmatics and exploring multi-modal interactions to help enhance the expressiveness of how users can ask questions about their data during the flow of visual analysis.},
author = {Setlur, Vidya and Battersby, Sarah E and Tory, Melanie and Gossweiler, Rich and Chang, Angel X},
doi = {10.1145/2984511.2984588},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Setlur et al. - 2016 - Eviza A Natural Language Interface for Visual Analysis(2).pdf:pdf},
isbn = {978-1-4503-4189-9},
journal = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology - UIST '16},
keywords = {ambiguity,natural language,parser,pragmatics,probabilistic grammar,visual data analysis,visualization},
mendeley-groups = {NLP},
pages = {365--377},
title = {{Eviza: A Natural Language Interface for Visual Analysis}},
url = {http://doi.acm.org/10.1145/2984511.2984588},
year = {2016}
}
@article{Hoque2017,
abstract = {Interactive visual data analysis is most productive when users can focus on answering the questions they have about their data, rather than focusing on how to operate the interface to the analysis tool. One viable approach to engaging users in interactive conversations with their data is a natural language interface to visualizations. These interfaces have the potential to be both more expressive and more accessible than other interaction paradigms. We explore how principles from language pragmatics can be applied to the flow of visual analytical conversations, using natural language as an input modality. We evaluate the effectiveness of pragmatics support in our system Evizeon, and present design considerations for conversation interfaces to visual analytics tools.},
author = {Hoque, Enamul and Setlur, Vidya and Tory, Melanie and Dykeman, Isaac},
doi = {10.1109/TVCG.2017.2744684},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Hoque et al. - 2017 - Applying Pragmatics Principles for Interaction with Visual Analytics.pdf:pdf},
isbn = {1077-2626 VO  - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Coherence,Data visualization,Natural languages,Pragmatics,Tools,Visual analytics,ambiguity,feedback,interaction,language pragmatics,natural language,visual analytics},
mendeley-groups = {NLP},
number = {c},
title = {{Applying Pragmatics Principles for Interaction with Visual Analytics}},
year = {2017}
}
@article{Gao2015,
abstract = {Answering questions with data is a difficult and time-consuming process. Visual dashboards and templates make it easy to get started, but asking more sophisticated questions often requires learning a tool designed for expert analysts. Natural language interaction allows users to ask questions directly in complex programs without having to learn how to use an interface. However, natural language is often ambiguous. In this work we propose a mixed-initiative approach to managing ambiguity in natural language interfaces for data visualization. We model ambiguity throughout the process of turning a natural language query into a visualization and use algorithmic disambiguation coupled with interactive ambiguity widgets. These widgets allow the user to resolve ambiguities by surfacing system decisions at the point where the ambiguity matters. Corrections are stored as constraints and influence subsequent queries. We have implemented these ideas in a system, DataTone. In a comparative study, we find that DataTone is easy to learn and lets users ask questions without worrying about syntax and proper question form.},
author = {Gao, T.a and Dontcheva, M.b and Adar, E.a and Liu, Z.b and Karahalios, K.c},
doi = {10.1145/2807442.2807478},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2015 - Datatone Managing ambiguity in natural language interfaces for data visualization.pdf:pdf},
isbn = {978-1-4503-3779-3},
journal = {Proceedings of the 28th Annual ACM Symposium on User Interface Software {\&} Technology - UIST '15},
mendeley-groups = {HILDA/Viz/System,NLP/viz-rec},
pages = {489--500},
title = {{Datatone: Managing ambiguity in natural language interfaces for data visualization}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84958249800{\&}partnerID=40{\&}md5=f0eb3ceb834a66e6d0eb6b59ffc57163},
year = {2015}
}

@article{Fast2018,
abstract = {Today's conversational agents are restricted to simple standalone commands. In this paper, we present Iris, an agent that draws on human conversational strategies to combine commands, allowing it to perform more complex tasks that it has not been explicitly designed to support: for example, composing one command to "plot a histogram" with another to first "log-transform the data". To enable this complexity, we introduce a domain specific language that transforms commands into automata that Iris can compose, sequence, and execute dynamically by interacting with a user through natural language, as well as a conversational type system that manages what kinds of commands can be combined. We have designed Iris to help users with data science tasks, a domain that requires support for command combination. In evaluation, we find that data scientists complete a predictive modeling task significantly faster (2.6 times speedup) with Iris than a modern non-conversational programming environment. Iris supports the same kinds of commands as today's agents, but empowers users to weave together these commands to accomplish complex goals.},
archivePrefix = {arXiv},
arxivId = {1707.05015},
author = {Fast, Ethan and Chen, Binbin and Mendelsohn, Julia and Bassen, Jonathan and Bernstein, Michael},
eprint = {1707.05015},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/Fast et al. - 2018 - Iris A Conversational Agent for Complex Tasks.pdf:pdf},
isbn = {9781450356206},
journal = {CHI 2018},
mendeley-groups = {NLP},
title = {{Iris: A Conversational Agent for Complex Tasks}},
url = {http://arxiv.org/abs/1707.05015},
year = {2018}
}

@inproceedings{Buneman2006,
 author = {Buneman, Peter and Chapman, Adriane and Cheney, James},
 title = {Provenance Management in Curated Databases},
 booktitle = {Proceedings of the 2006 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '06},
 year = {2006},
 isbn = {1-59593-434-0},
 location = {Chicago, IL, USA},
 pages = {539--550},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1142473.1142534},
 doi = {10.1145/1142473.1142534},
 acmid = {1142534},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {curation, provenance, storage},
} 

@article{Cui2003,
 author = {Cui, Y. and Widom, J.},
 title = {Lineage Tracing for General Data Warehouse Transformations},
 journal = {The VLDB Journal},
 issue_date = {May 2003},
 volume = {12},
 number = {1},
 month = may,
 year = {2003},
 issn = {1066-8888},
 pages = {41--58},
 numpages = {18},
 url = {http://dx.doi.org/10.1007/s00778-002-0083-8},
 doi = {10.1007/s00778-002-0083-8},
 acmid = {775456},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
 keywords = {Data lineage, Data warehouse, Inverse, Lineage tracing, Transformation},
} 
@article{Embley1989,
 author = {Embley, David W.},
 title = {NFQL: The Natural Forms Query Language},
 journal = {ACM Trans. Database Syst.},
 issue_date = {June 1989},
 volume = {14},
 number = {2},
 month = jun,
 year = {1989},
 issn = {0362-5915},
 pages = {168--211},
 numpages = {44},
 url = {http://doi.acm.org/10.1145/63500.64125},
 doi = {10.1145/63500.64125},
 acmid = {64125},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
@inproceedings{Woodruff1997,
 author = {Woodruff, Allison and Stonebraker, Michael},
 title = {Supporting Fine-grained Data Lineage in a Database Visualization Environment},
 booktitle = {Proceedings of the Thirteenth International Conference on Data Engineering},
 series = {ICDE '97},
 year = {1997},
 isbn = {0-8186-7807-0},
 pages = {91--102},
 numpages = {12},
 url = {http://dl.acm.org/citation.cfm?id=645482.653450},
 acmid = {653450},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {anomalies, base data, data processing history, data visualisation, database visualization environment, debugging, error sources, fine-grained data lineage, large data sets, lazy algorithm, limited information, lineage guarantees, metadata, object-relational database management system, processed data sets, processing operators, tracing, verification, weak inversion},
} 
@inproceedings{Yu2006,
 author = {Yu, Cong and Jagadish, H. V.},
 title = {Schema Summarization},
 booktitle = {Proceedings of the 32Nd International Conference on Very Large Data Bases},
 series = {VLDB '06},
 year = {2006},
 location = {Seoul, Korea},
 pages = {319--330},
 numpages = {12},
 url = {http://dl.acm.org/citation.cfm?id=1182635.1164156},
 acmid = {1164156},
 publisher = {VLDB Endowment},
} 
@article{McHugh1997,
author = {McHugh, J and Abiteboul, S and Goldman, R and Quass, D and Widom, J},
file = {:Users/dolee/Library/Application Support/Mendeley Desktop/Downloaded/McHugh et al. - 1997 - Lorel A database management system for semistructured data.pdf:pdf},
journal = {SIGMOD Record},
keywords = {annotation Peter},
number = {3},
pages = {238--247},
title = {{Lore: A database management system for semistructured data}},
volume = {26},
year = {1997}
}
